#!groovy
node("harvester-vpn-1") {
  def rootPath = "/root/go/src/github.com/rancher/tfp-automation/"
  def homePath = "/home/ubuntu/jenkins/workspace/rancher_qa/caleb-harvester-e2e2"
  def modulesPath = "modules/sanity/harvester"
  def testRootPath = "/root/go/src/github.com/rancher/tests/validation/"
  def testsDir = "github.com/rancher/tfp-automation/tests/${env.TEST_PACKAGE}"
  def golangTestDir = "github.com/rancher/tests/validation/${env.GO_TEST_PACKAGE}"
  def golangHvstDir = "github.com/rancher/tests/validation/harvester"
  def hvstTestCase = "-run ^TestHarvesterTestSuite\$"
  def filename = "config.yml"
  def job_name = "${JOB_NAME}"
  if (job_name.contains('/')) { 
    job_names = job_name.split('/')
    job_name = job_names[job_names.size() - 1] 
  }
  def golangTestContainer = "${job_name}${env.BUILD_NUMBER}_test2"
  def testContainer = "${job_name}${env.BUILD_NUMBER}_test"
  def imageName = "tfp-automation-validation-${job_name}${env.BUILD_NUMBER}"
  def testResultsOut = "results.xml"
  def testResultsJSON = "results.json"
  def envFile = ".env"
  def config = env.CONFIG
  def adminToken = ""
  def privateRegistry = ""
  def validationVolume = "ValidationSharedVolume-${job_name}${env.BUILD_NUMBER}"

  def infraBranch = "${env.INFRA_BRANCH}"
  if ("${env.INFRA_BRANCH}" != "null" && "${env.INFRA_BRANCH}" != "") {
        infraBranch = "${env.INFRA_BRANCH}"
  }
  def testBranch = "${env.TEST_BRANCH}"
  if ("${env.TEST_BRANCH}" != "null" && "${env.TEST_BRANCH}" != "") {
        testBranch = "${env.TEST_BRANCH}"
  }
  def infraRepo = scm.userRemoteConfigs
  if ("${env.INFRA_REPO}" != "null" && "${env.INFRA_REPO}" != "") {
    infraRepo = [[url: "${env.INFRA_REPO}"]]
  }
  def testRepo = scm.userRemoteConfigs
  if ("${env.TEST_REPO}" != "null" && "${env.TEST_REPO}" != "") {
    testRepo = [[url: "${env.TEST_REPO}"]]
  }
  def timeout = "${env.TIMEOUT}"
  if ("${env.TIMEOUT}" != "null" && "${env.TIMEOUT}" != "") {
        timeout = "${env.TIMEOUT}" 
  }

    wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm', 'defaultFg': 2, 'defaultBg':1]) {
        withFolderProperties {
            paramsMap = []
            params.each {
                if (it.value && it.value.trim() != "") {
                    paramsMap << "$it.key=$it.value"
                }
            }
            withCredentials([ string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                              string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
                              string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),
                              string(credentialsId: 'AWS_SSH_RSA_KEY', variable: 'AWS_SSH_RSA_KEY'),
                              string(credentialsId: 'AWS_RSA_KEY_NAME', variable: 'AWS_RSA_KEY_NAME'),
                              string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
                              string(credentialsId: 'ADMIN_PASSWORD', variable: 'ADMIN_PASSWORD')]) {
          
                withEnv(paramsMap) {

                    stage('Setup Harvester Environment') {
                        sh returnStdout: true, script: 'wget -qO ./jq https://github.com/jqlang/jq/releases/latest/download/jq-linux-amd64'
                        sh returnStdout:true, script: 'chmod a+x ./jq'

                        sh returnStdout: true, script: 'wget -qO ./yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64'
                        sh returnStdout:true, script: 'chmod a+x ./yq'

                        sh returnStdout: true, script:  'wget -qO ./kubectl "https://dl.k8s.io/release/\$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"'
                        sh returnStdout: true, script:  'chmod a+x ./kubectl'

                        dir(".ssh") {
                            def decoded = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
                            writeFile file: AWS_SSH_KEY_NAME, text: decoded
                    
                            def decodedRsa = new String(AWS_SSH_RSA_KEY.decodeBase64())
                            writeFile file: AWS_RSA_KEY_NAME, text: decodedRsa
                        }

                        writeFile file: 'seeder.yaml', text: SEEDER_KUBECONFIG
                        // need to inject sshKey into clusterConfig object of nodeManifest so that passwordless SSH works
                        writeFile file: 'node_manifest.yaml', text: NODE_MANIFEST
                        // will only work for single node clusters unless we write a loop
                        sh "./yq e '.spec.nodes.[0].inventoryReference.name = \"${HARVESTER_INVENTORY_NODE}\"' -i node_manifest.yaml"
                        
                        sh "./yq e '.metadata.name = \"${HARVESTER_CLUSTER_NAME}\"' -i node_manifest.yaml"

                        sh "./yq e '.spec.version = \"${HARVESTER_VERSION}\"' -i node_manifest.yaml"
                        sh "chmod 600 .ssh/${AWS_SSH_KEY_NAME}"
                        def publicSSHKey = sh(script: "ssh-keygen -f .ssh/${AWS_SSH_KEY_NAME} -y", returnStdout: true).trim()
                        sh "./yq e '.spec.clusterConfig.sshKeys.[0] = \"${publicSSHKey}\"' -i node_manifest.yaml"
                        

                        sh '''#!/bin/bash
                        
                        export KUBECONFIG=seeder.yaml
                        ./kubectl delete clusters.metal/$HARVESTER_CLUSTER_NAME -n tink-system || true
                        sleep 30

                        ./kubectl apply -f node_manifest.yaml

                        export inode=""
                        while [[ -z "$inode" ]]; do
                            export inode=$(./kubectl get -n tink-system inventories/$HARVESTER_INVENTORY_NODE -o jsonpath='{.status.pxeBootConfig.address}')
                            sleep 2
                        done
                        echo "harvester IP address"
                        echo $inode

                        sleep 240

                        until ping -c1 -W1 $inode; do sleep 2; done
                        echo "able to ping node, moving on to get harvester kubeconfig"

                        sleep 660

                        until timeout 60 ssh -n -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i .ssh/$AWS_SSH_KEY_NAME rancher@$inode 'sudo cat /etc/rancher/rke2/rke2.yaml'; do sleep 5; done
                        echo "ssh shows rke2.yaml is up, downloading now.."

                        ssh -n -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i .ssh/$AWS_SSH_KEY_NAME rancher@$inode 'sudo cat /etc/rancher/rke2/rke2.yaml' > harvester.yaml
                        sed -i "s#server: https://127.0.0.1:6443#server: https://$inode:6443#g" harvester.yaml

                        export KUBECONFIG=harvester.yaml

                        sleep 300

                        ./kubectl get pods -A
                        ./kubectl rollout status deployment -n harvester-system harvester
                        ./kubectl rollout status deployment -n cattle-system rancher

                        '''

                        config = config.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY)
                        config = config.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID)
                        

                        writeFile file: filename, text: config

                        def RANCHER_PASSWORD = sh (
                          script: "./yq '.rancher.adminPassword' ${filename}",
                          returnStdout: true
                        ).trim()

                        sh '''#!/bin/bash
                        export KUBECONFIG=seeder.yaml
                        export inode=$(./kubectl get clusters.metal/$HARVESTER_CLUSTER_NAME -n tink-system -o jsonpath='{.status.clusterAddress}')

                        until [[ "$(curl -s -L --insecure -o /dev/null -w "%{http_code}\n" "https://$inode")" == "200" ]]; do sleep 5; done; echo "https://$inode is healthy"
                        
                        jsonOutput=$(curl --insecure -d '{"username" : "admin", "password" : "admin", "responseType" : "json"}'  https://$inode/v3-public/localproviders/local?action=login)
                        
                        token=$(echo $jsonOutput | jq -cr .token)
                        userID=$(echo $jsonOutput | jq -cr .userId)


                        jsonData=$( jq -n --arg password "password1234" '{"newPassword" : $password}')
                        curl --insecure --user "$token" -X POST -H 'Accept: application/json' -H 'Content-Type: application/json' -d "$jsonData" https://$inode/v3/users/$userID?action=setpassword

                        echo "$token" > login.token
                        echo "$inode" > host.txt

                        '''

                        def TOKEN = sh (
                          script: "cat login.token",
                          returnStdout: true
                        ).trim()

                        sh "./yq e '.harvester.adminToken = \"${TOKEN}\"' -i ${filename}"

                        def HOST = sh (
                          script: "cat host.txt",
                          returnStdout: true
                        ).trim()


                        sh "./yq e '.harvester.host = \"${HOST}\"' -i ${filename}"


                        sh "./yq e '.terraform.harvesterCredentials.kubeconfigContent = load_str(\"harvester.yaml\")' -i ${filename}"

                        config = sh(script: "cat ${filename}", returnStdout: true).trim()

                        
                    }
                    stage('Checkout Infrastructure Repo') {
                      checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${infraBranch}"]],
                                extensions: scm.extensions + [[$class: 'CleanCheckout']],
                                userRemoteConfigs: infraRepo
                              ])
                     }

                    stage('Configure and Build') {

                        writeFile file: filename, text: config
                
                        dir(".ssh") {
                            def decoded = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
                            writeFile file: AWS_SSH_KEY_NAME, text: decoded
                    
                            def decodedRsa = new String(AWS_SSH_RSA_KEY.decodeBase64())
                            writeFile file: AWS_RSA_KEY_NAME, text: decodedRsa
                        }

                        env.CATTLE_TEST_CONFIG=rootPath+filename

                        sh "./configure.sh"
                        sh "./build.sh"

                        sh "docker volume create --name ${validationVolume}"
                        
                        sh returnStdout: true, script: 'wget -qO ./yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64'
                        sh returnStdout:true, script: 'chmod a+x ./yq'

                        sh returnStdout: true, script:  'wget -qO ./kubectl "https://dl.k8s.io/release/\$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"'
                        sh returnStdout: true, script:  'chmod a+x ./kubectl'
                        
                        def harvesterKubeconfig = sh (
                          script: "./yq '.terraform.harvesterCredentials.kubeconfigContent' ${filename}",
                          returnStdout: true
                        ).trim()
                        
                        writeFile file: "harvester.yaml", text: harvesterKubeconfig
                        writeFile file: 'harvester_config.yaml', text: HARVESTER_CONFIG

                        sh '''#!/bin/bash
                        export KUBECONFIG=harvester.yaml

                        ./kubectl apply -f harvester_config.yaml
                        '''
                     }

                    stage('Run Infrastructure TFP Test') {
                        try {
                            sh """
                            docker run -v ${validationVolume}:/root --name ${testContainer} -t --env-file ${envFile} ${imageName} sh -c "
                            /root/go/bin/gotestsum --format standard-verbose --packages=${testsDir} --junitfile ${testResultsOut} --jsonfile ${testResultsJSON} -- -timeout=${timeout} -v ${params.TEST_CASE}"
                            """
                            sh "docker cp ${testContainer}:${rootPath}${filename} ${filename}"
                            
                          
                        } catch(err) {
                            echo "Test run had failures. Collecting results... ${err}"
                            error err
                        }
                     } 

                    stage('Checkout Test Repo') {
                        checkout([  
                                    $class: 'GitSCM',
                                    branches: [[name: "*/${testBranch}"]],
                                    extensions: scm.extensions + [[$class: 'CleanCheckout']],
                                    userRemoteConfigs: testRepo
                                ])
                    }

                    dir ("./") {
                        stage('Configure and Build') {
                          if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
                            dir("./validation/.ssh") {
                              def decoded = new String(AWS_SSH_PEM_KEY.decodeBase64())
                              writeFile file: AWS_SSH_KEY_NAME, text: decoded
                            }
                          }               
                          dir("./validation") {             
                            sh "docker cp ${testContainer}:${rootPath}${filename} ${filename}"
                            env.CATTLE_TEST_CONFIG = testRootPath+filename
                          }
                          dir("./") {     
                            sh "./validation/configure.sh"
                            sh "docker build . -f ./validation/Dockerfile.validation -t ${imageName}"
                            sh "docker volume create --name tests${validationVolume}"

                            sh "docker cp ${testContainer}:${rootPath}${filename} ${filename}"
                          }
                        }
                        stage('Connect Rancher -> Harvester') {

                          try {
                            // this test also writes harvesterCloudCredentials to the config
                            sh """
                            docker run -v tests${validationVolume}:/root --name hvst${golangTestContainer} -t --env-file ${envFile} ${imageName} sh -c "/root/go/bin/gotestsum --format standard-verbose --packages=${golangHvstDir} --junitfile ${testResultsOut} -- -tags=${TAGS} ${hvstTestCase} -timeout=${timeout} -v "
                            """
                          } catch(err) {
                            echo "${err} Unable to connect harvester to new rancher setup. Aborting"
                          }
                          
                        }
                        stage('Run Validation Tests') {

                          try {
                            sh """

                            docker cp ${testContainer}:${rootPath}modules/sanity/harvester/ .;
                            pwd;
                            ls -la harvester/ ;
                            docker run -v tests${validationVolume}:/root --name ${golangTestContainer} -t --env-file ${envFile} ${imageName} sh -c "/root/go/bin/gotestsum --format standard-verbose --packages=${golangTestDir} --junitfile ${testResultsOut} -- -tags=${TAGS} ${GO_TEST_CASE} -timeout=${timeout} -v ;"
                            """
                              
                          } catch(err) {
                            echo "${err} Validation tests had failures. Aborting"
                          }
                          sh """
                          docker stop ${golangTestContainer} || true
                          docker stop hvst${golangTestContainer} || true
                          docker rm ${golangTestContainer} || true
                          docker rm hvst${golangTestContainer} || true
                          
                          docker rmi ${imageName} || true
                          
                          """
                          
                        }
                    }//dir
                    stage('Cleanup terraform resources'){
                      try {

                        dir ("./") {
                          if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
                            dir("./harvester/.ssh") {
                              def decoded = new String(AWS_SSH_PEM_KEY.decodeBase64())
                              writeFile file: AWS_SSH_KEY_NAME, text: decoded
                            }
                          }
                          
                          sh """
                          docker run --rm -v \$(pwd)/harvester:/terraform-files \
                              -v \$(pwd)/harvester/.ssh:/root/go/src/github.com/rancher/tfp-automation/.ssh \
                              -w /terraform-files hashicorp/terraform:latest \
                              destroy --auto-approve
                          """

                          writeFile file: 'seeder.yaml', text: SEEDER_KUBECONFIG

                          sh returnStdout: true, script:  'wget -qO ./kubectl "https://dl.k8s.io/release/\$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"'
                          sh returnStdout: true, script:  'chmod a+x ./kubectl'
                          sh '''#!/bin/bash

                            export KUBECONFIG=seeder.yaml
                            ./kubectl delete clusters.metal/$HARVESTER_CLUSTER_NAME -n tink-system || true
                          '''
                          
                        }
                      }
                      catch(err) {
                        echo "${err} captured, there be dragons..."
                      }
                      sh "docker stop ${testContainer}"
                      sh "docker volume rm ${validationVolume} || true"
                      sh "docker rm ${testContainer} || true"
                      } //cleanup
                } //params
            } //credentials
        } //folder properties
    } //wrap
} // node